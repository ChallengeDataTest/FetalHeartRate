{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20fab4cd",
   "metadata": {},
   "source": [
    "# Le but de ce notebook est d'identifier des caractéristiques très simples permettant d'analyser des battements de coeur de foetus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e01dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install hyperopt\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# permet de charger les fichiers matlab (*.mat)\n",
    "from scipy.io import loadmat\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "\n",
    "# le répertoire de travail\n",
    "directory = os.path.abspath('')\n",
    "\n",
    "# répertoire où se trouvent toutes les données associés à ce challenge\n",
    "data_directory = os.path.join(directory, 'Data')\n",
    "\n",
    "# fichier CSV contenant les targets (1 / 0)\n",
    "targets_path = os.path.join(data_directory, 'CTG_Challenge_files_GroundTruth.csv')\n",
    "\n",
    "# répertoire où se trouvent les fichiers de données matlab\n",
    "matlab_directory = os.path.join(data_directory, 'ctg_workshop_database')\n",
    "\n",
    "# dans l'électrocardiogramme, nous avons 4 mesures par seconde\n",
    "# chaque mesure correspondent à au nombre de battements de coeurs par minute\n",
    "elements_en_1s = 4\n",
    "elements_en_1minute = int(elements_en_1s*60)\n",
    "elements_en_5minutes = 5*elements_en_1minute\n",
    "elements_en_30minutes = 30*elements_en_1minute\n",
    "elements_en_1heure = 60*elements_en_1minute\n",
    "\n",
    "# retourne tous les fichiers matlab présents dans le repertoire 'path'\n",
    "def all_mat_files_in_directory(path: str):\n",
    "    return [os.path.join(path,f) for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith('.mat')]\n",
    "\n",
    "# calcule la moyenne de la séquence ''fhr' en ignorant les NaN\n",
    "def moyenne(fhr):\n",
    "    return fhr[~np.isnan(fhr)].mean()\n",
    "\n",
    "# calcule la médiane de la séquence ''fhr' en ignorant les NaN\n",
    "def mediane(fhr):\n",
    "    return np.nanmedian(fhr)\n",
    "\n",
    "# calcule la std dev de la séquence ''fhr' en ignorant les NaN\n",
    "def ecart_type(fhr):\n",
    "    return fhr[~np.isnan(fhr)].std()\n",
    "\n",
    "# nombre d elements NaN dans la séquence 'fhr'\n",
    "def nan_count(fhr):\n",
    "    return np.count_nonzero(np.isnan(fhr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7142cf8",
   "metadata": {},
   "source": [
    "# PRIVE: Chargement des données d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d009cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chemin vers tous les fichiers matlab de la base d'entraînement\n",
    "id_to_path = dict()\n",
    "for filename in all_mat_files_in_directory(matlab_directory):\n",
    "    filename_without_extension = os.path.splitext(os.path.basename(filename))[0]    \n",
    "    id = int(filename_without_extension.lstrip('0'))\n",
    "    id_to_path[id] = filename\n",
    "\n",
    "# on charge les targets associés à chaque fichier d'entraînement\n",
    "targets_df = pd.read_csv(targets_path)\n",
    "id_to_target = dict()\n",
    "for _, row in targets_df.iterrows():\n",
    "    id_to_target[row['ChallengeID']] = row['TrueOutcome']\n",
    "\n",
    "# lecture des battements de coeurs des foetus\n",
    "id_to_fhr = dict()\n",
    "all_lengths = []\n",
    "for id, path in id_to_path.items():\n",
    "    matlab_file = loadmat(path)\n",
    "    id_to_fhr[id] = matlab_file['fhr'].flatten()\n",
    "    # on ne garde que la dernière heure #//?D\n",
    "    id_to_fhr[id] = id_to_fhr[id][-60*4*60:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d15ddac",
   "metadata": {},
   "source": [
    "# PRIVE: Calcul de statistiques sur ces données d'entraînement\n",
    "## (pour faciliter la recherche des caractéristiques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a19a106",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "targets = []\n",
    "moyenne_full = []\n",
    "mediane_full = []\n",
    "ecart_type_full = []\n",
    "count_full = []\n",
    "nan_count_full = []\n",
    "moyenne_1ere_heure = []\n",
    "mediane_1ere_heure = []\n",
    "ecart_type_1ere_heure = []\n",
    "count_1ere_heure = []\n",
    "nan_count_1ere_heure = []\n",
    "moyenne_derniere_heure = []\n",
    "mediane_derniere_heure = []\n",
    "ecart_type_derniere_heure = []\n",
    "count_derniere_heure = []\n",
    "nan_count_derniere_heure = []\n",
    "\n",
    "for id in list(id_to_path.keys()):\n",
    "    ids.append(id)\n",
    "    targets.append(id_to_target[id])\n",
    "    \n",
    "    fhr_full = id_to_fhr[id]\n",
    "    \n",
    "    moyenne_full.append(moyenne(fhr_full))\n",
    "    mediane_full.append(mediane(fhr_full))\n",
    "    ecart_type_full.append(ecart_type(fhr_full)) \n",
    "    count_full.append(fhr_full.size)\n",
    "    nan_count_full.append(nan_count(fhr_full))\n",
    "\n",
    "    fhr_1ere_heure = fhr_full[:elements_en_1heure]\n",
    "    moyenne_1ere_heure.append(moyenne(fhr_1ere_heure))\n",
    "    mediane_1ere_heure.append(mediane(fhr_1ere_heure))\n",
    "    ecart_type_1ere_heure.append(ecart_type(fhr_1ere_heure)) \n",
    "    count_1ere_heure.append(fhr_1ere_heure.size)\n",
    "    nan_count_1ere_heure.append(nan_count(fhr_1ere_heure))\n",
    "    \n",
    "    fhr_derniere_heure = fhr_full[-elements_en_1heure:]\n",
    "    moyenne_derniere_heure.append(moyenne(fhr_derniere_heure))\n",
    "    mediane_derniere_heure.append(mediane(fhr_derniere_heure))\n",
    "    ecart_type_derniere_heure.append(ecart_type(fhr_derniere_heure)) \n",
    "    count_derniere_heure.append(fhr_derniere_heure.size)\n",
    "    nan_count_derniere_heure.append(nan_count(fhr_derniere_heure))\n",
    "\n",
    "    \n",
    "# Sauvegarde de ces statistiques dans un DataFrame\n",
    "fhr_stats = pd.DataFrame(\n",
    "    {'ids': ids,\n",
    "    'targets': targets,\n",
    "    'moyenne_full' : moyenne_full,\n",
    "    'mediane_full' : mediane_full,\n",
    "    'ecart_type_full' : ecart_type_full,\n",
    "    'count_full' : count_full,\n",
    "    'nan_count_full' : nan_count_full,\n",
    "    'moyenne_1ere_heure' : moyenne_1ere_heure,\n",
    "    'mediane_1ere_heure' : mediane_1ere_heure,\n",
    "    'ecart_type_1ere_heure' : ecart_type_1ere_heure,\n",
    "    'count_1ere_heure' : count_1ere_heure,\n",
    "    'nan_count_1ere_heure' : nan_count_1ere_heure,\n",
    "    'moyenne_derniere_heure' : moyenne_derniere_heure,\n",
    "    'mediane_derniere_heure' : mediane_derniere_heure,\n",
    "    'ecart_type_derniere_heure' : ecart_type_derniere_heure,\n",
    "    'count_derniere_heure' : count_derniere_heure,\n",
    "    'nan_count_derniere_heure' : nan_count_derniere_heure,\n",
    "    })\n",
    "\n",
    "# on sauvegarde ces stats sur le disque\n",
    "fhr_stats.to_csv(os.path.join(directory, 'fhr_stats.csv'), index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1bd514",
   "metadata": {},
   "source": [
    "# PRIVE: méthodes permettant l'affichage d'électrocardiogrammes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d1cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "def interpolate_nans(array):\n",
    "    not_nan = ~np.isnan(array)\n",
    "    indices = np.arange(len(array))\n",
    "    interpolated_array = np.copy(array)\n",
    "    interpolated_array[np.isnan(array)] = np.interp(indices[np.isnan(array)], indices[not_nan], array[not_nan])\n",
    "    return interpolated_array\n",
    "\n",
    "def display_electrocardiogram(id: int, start_minut:float, duration_in_minuts: float, display_mean: bool = True, interpolate_missing_values:bool = True, min_y_value: int = None, max_y_value: int = None):\n",
    "\n",
    "    # nous ne gardons que les 28 dernières minutes de l'enregistrement:\n",
    "    # (pour être aligné avec les fichiers pdf du répertoire 'ctg_data')\n",
    "    # Il y a 4 mesures par seconde: nous devons donc garder les 4*60*'last_minuts_to_keep' dernières valeurs\n",
    "    \n",
    "    fhr_full = loadmat(id_to_path[id])['fhr'].ravel()\n",
    "\n",
    "    start_idx = int(start_minut*4*60)\n",
    "    if start_idx<0: \n",
    "        start_idx+=len(fhr_full)\n",
    "    start_idx = max(0, start_idx-1)\n",
    "    end_idx = min( start_idx+1+int(duration_in_minuts*4*60) , len(fhr_full) )\n",
    "    \n",
    "    fhr = fhr_full[start_idx:end_idx]\n",
    "    if interpolate_missing_values:\n",
    "        fhr = interpolate_nans(fhr)\n",
    "    \n",
    "    # nombre d'éléments dans l'électrocardiogramme\n",
    "    n = len(fhr)\n",
    "    \n",
    "    # Create an array of time points (assuming each heart rate measurement is taken at regular intervals)\n",
    "    time_in_minuts = np.arange(n)/(60*4)\n",
    "    # Plot the heart rate data\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.plot(time_in_minuts, fhr, linestyle='-', color='black', linewidth=1)\n",
    "    # Formater les ticks pour afficher le temps au format hh:mm\n",
    "    def format_func(time_in_minuts, tick_number):\n",
    "        #time_in_minuts = int(time_in_minuts/(60*4))\n",
    "        hours = int(time_in_minuts) // 60\n",
    "        minutes = int(time_in_minuts) % 60\n",
    "        return f'{hours:02d}:{minutes:02d}'\n",
    "    plt.gca().xaxis.set_major_formatter(ticker.FuncFormatter(format_func))\n",
    "    comment = 'sujet sain' if id_to_target[id] == 0 else 'sujet malade'\n",
    "    \n",
    "    if display_mean:\n",
    "        observed_mean = int(moyenne(fhr_full))\n",
    "        plt.axhline(y=observed_mean, color='red', linewidth=1, linestyle='-', label='Moyenne: '+str(observed_mean))\n",
    "        # Annotate the y-value on the vertical axis\n",
    "        plt.text(x=0, y=observed_mean, s=f'{observed_mean:.0f}', color='red', va='center', ha='right')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Temps (minutes)', fontsize=15)\n",
    "    plt.ylabel('Battements de coeur par minutes', fontsize=15)\n",
    "    plt.title(f\"Electrocardiogramme pour un {comment} ({id})\", fontsize=15)\n",
    "    plt.xlim(0, max(time_in_minuts))\n",
    "    plt.ylim(min_y_value or 60, max_y_value or 180)\n",
    "    # Display grid\n",
    "    plt.grid(True)\n",
    "\n",
    "    if display_mean:\n",
    "        plt.legend()\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "def display_electrocardiograms(count:int, start_minut:int, duration_in_minuts: int, label: int, start_id:int = 1, display_mean: bool = True, interpolate_missing_values:bool = True, min_y_value: int = None, max_y_value: int = None):\n",
    "    displayed_count = 0\n",
    "    for idx in range(start_id, start_id+300,1):\n",
    "        id = idx if idx <=300 else idx-300\n",
    "        if id_to_target[id] != label:\n",
    "            continue\n",
    "        display_electrocardiogram(id, start_minut, duration_in_minuts, display_mean=display_mean, interpolate_missing_values=interpolate_missing_values, min_y_value=min_y_value, max_y_value=max_y_value)\n",
    "        displayed_count+= 1\n",
    "        if displayed_count>=count:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5bab3a",
   "metadata": {},
   "source": [
    "# Affichage d'exemples d'électrocardiogrammes pour des sujets sains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91be5329",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_a_afficher = 100\n",
    "start_minut = 0\n",
    "duration_in_minuts = 120\n",
    "label = 0  #0 pour les sujets sains , 1 pour les sujets malades\n",
    "start_id = 50 # id du 1er élément à afficher\n",
    "\n",
    "display_electrocardiograms(nombre_a_afficher, start_minut, duration_in_minuts, label, start_id, display_mean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceec7c4c",
   "metadata": {},
   "source": [
    "# Affichage d'exemples d'électrocardiogrammes pour des sujets malades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad19cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_a_afficher = 100\n",
    "start_minut = -120\n",
    "duration_in_minuts = 90\n",
    "label = 1  #0 pour les sujets sains , 1 pour les sujets malades\n",
    "start_id = 50 # id du 1er élément à afficher\n",
    "\n",
    "\n",
    "display_electrocardiograms(nombre_a_afficher, start_minut, duration_in_minuts, label, start_id, display_mean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495f78b8",
   "metadata": {},
   "source": [
    "# PRIVE: Liste des caractéristiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505aa43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "id_to_data = id_to_fhr\n",
    "\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def proportion_in_interval(id, min_value: float, max_value: float) -> float:\n",
    "    fhr = id_to_data[id]\n",
    "    total_points = np.count_nonzero(~np.isnan(fhr))\n",
    "    if total_points<=0:\n",
    "        return 0\n",
    "    total_points_in_interval = np.count_nonzero((fhr > min_value) & (fhr < max_value) )\n",
    "    return total_points_in_interval/total_points\n",
    "\n",
    "# calcul de la écart-type\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def compute_id_std_dev(id: int):\n",
    "    return ecart_type(id_to_data[id])\n",
    "    \n",
    "# calcul de l'etendue de la séquence associée à l'id 'id' en ignorant les NaN\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def compute_id_range(id: int):\n",
    "    data = id_to_data[id]\n",
    "    return max(data)-min(data)\n",
    "   \n",
    "# calcul de la moyenne de la séquence associée à l'id 'id' en ignorant les NaN\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def compute_id_mean(id: int):\n",
    "    return moyenne(id_to_data[id])\n",
    "\n",
    "# calcul de la médiane de la séquence associée à l'id 'id' en ignorant les NaN\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def compute_id_median(id: int):\n",
    "    return mediane(id_to_data[id])\n",
    "\n",
    "# calcul de la moyenne sur l'ensemble du dataset\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def global_mean() -> float :\n",
    "    moyennes = []\n",
    "    for id,data in id_to_data.items():\n",
    "        moyennes.append(compute_id_mean(id)) \n",
    "    return np.mean(moyennes)\n",
    "\n",
    "\n",
    "\n",
    "# calcul de l'écart type autour de la médiane de la séquence associée à l'id 'id' en ignorant les NaN\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def compute_id_std_median(id: int) -> float:\n",
    "    data = id_to_data[id]\n",
    "    median = compute_id_median(id)\n",
    "    deviations = data - median\n",
    "    squared_deviations = deviations ** 2\n",
    "    variance = np.nanmean(squared_deviations)\n",
    "    std_deviation = np.sqrt(variance)\n",
    "    return std_deviation\n",
    "\n",
    "# calcul de la médiane sur l'ensemble du dataset\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def global_median() -> float :\n",
    "    medianes = []\n",
    "    for id,data in id_to_data.items():\n",
    "        medianes.append(compute_id_median(id)) \n",
    "    return np.mean(medianes)\n",
    "\n",
    "# calcul du % de fois où une valeur a été passée\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def percentage_crossings(id: int, target_value: int) -> float:\n",
    "    series = id_to_data[id]\n",
    "    # Remove NaN values\n",
    "    valid_indices = ~np.isnan(series)\n",
    "    series = series[valid_indices]\n",
    "    if len(series) == 0:\n",
    "        return 0.0\n",
    "    # Create a boolean array where True indicates the value is greater than the specified value\n",
    "    above_value = series > target_value\n",
    "    # Calculate the difference of the boolean array\n",
    "    # A change from False to True or True to False indicates a crossing\n",
    "    crossings = np.diff(above_value.astype(int))\n",
    "    # Count the number of crossings\n",
    "    num_crossings = np.sum(np.abs(crossings))\n",
    "    # Return the % of crossing\n",
    "    return num_crossings/len(series)\n",
    "\n",
    "\n",
    "# calcul du nombre de passage par une valeur en 5 minutes\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def count_crossing_in_5minutes(id: int, target_value: int) -> float:\n",
    "    return percentage_crossings(id, target_value)*elements_en_5minutes\n",
    "\n",
    "\n",
    "# 1ere caracteristique version 1A : sujet sain si le pourcentage de points dans un intervalle donné est supérieur à un seuil (avec ajustement à la moyenne).\n",
    "def calcul_caracteristique1A(id: int, hyperparameters: dict, suffix: str) -> int:\n",
    "    min_value = hyperparameters['min_value_'+suffix]\n",
    "    min_value += compute_id_mean(id)-global_mean()\n",
    "    max_value = min_value +hyperparameters['range_'+suffix]\n",
    "    return 0 if proportion_in_interval(id, min_value, max_value) > hyperparameters['seuil_'+suffix] else 1\n",
    "\n",
    "# 1ere caracteristique version 1B : sujet sain si le pourcentage de points dans un intervalle donné est supérieur à un seuil (sans ajustement à la moyenne).\n",
    "def calcul_caracteristique1B(id: int, hyperparameters: dict, suffix: str) -> int:\n",
    "    min_value = hyperparameters['min_value_'+suffix]\n",
    "    max_value = min_value  +hyperparameters['range_'+suffix]\n",
    "    return 0 if proportion_in_interval(id, min_value, max_value) > hyperparameters['seuil_'+suffix] else 1\n",
    "\n",
    "# 3eme caracteristique: sujet sain si l'étendue de l'électrocardiogramme est inférieur à un seuil.\n",
    "def calcul_caracteristique3(id: int, hyperparameters: dict, suffix: str) -> int:\n",
    "    return 0 if compute_id_range(id)< hyperparameters['seuil_'+suffix] else 1\n",
    "\n",
    "# 4eme caracteristique: sujet sain si le pourcentage de points autour de la moyenne est supérieur à un seuil.\n",
    "def calcul_caracteristique4A(id: int, hyperparameters: dict, suffix: str) -> int:\n",
    "    range = hyperparameters['range_'+suffix]\n",
    "    moyenne = compute_id_mean(id)\n",
    "    return 0 if proportion_in_interval(id, moyenne-range, moyenne+range) > hyperparameters['seuil_'+suffix] else 1\n",
    "\n",
    "# caracteristique 4B: sujet sain si le pourcentage de points autour de la médiane est supérieur à un seuil.\n",
    "def calcul_caracteristique4B(id: int, hyperparameters: dict, suffix: str) -> int:\n",
    "    range = hyperparameters['range_'+suffix]\n",
    "    median = compute_id_median(id)\n",
    "    return 0 if proportion_in_interval(id, median-range, median+range) > hyperparameters['seuil_'+suffix] else 1\n",
    "\n",
    "# caracteristique 5A: sujet sain si la moyenne de l'électrocardiogramme est dans un intervalle donné\n",
    "def calcul_caracteristique5A(id: int, hyperparameters: dict, suffix: str) -> int:\n",
    "    min_value = hyperparameters['min_value_'+suffix]\n",
    "    max_value = min_value + hyperparameters['range_'+suffix]\n",
    "    moyenne = compute_id_mean(id)\n",
    "    return 0 if ((moyenne>=min_value) and (moyenne<=max_value)) else 1\n",
    "    \n",
    "# caracteristique 5B: sujet sain si la médiane de l'électrocardiogramme est dans un intervalle donné\n",
    "def calcul_caracteristique5B(id: int, hyperparameters: dict, suffix: str) -> int:\n",
    "    min_value = hyperparameters['min_value_'+suffix]\n",
    "    max_value = min_value + hyperparameters['range_'+suffix]\n",
    "    median = compute_id_median(id)\n",
    "    return 0 if ((median>=min_value) and (median<=max_value)) else 1\n",
    "\n",
    "# caracteristique 6: sujet sain si le % de points au dessus de la moyenne de l'électrocardiogramme est inférieur à un seuil.\n",
    "def calcul_caracteristique6(id: int, hyperparameters: dict, suffix: str) -> int:\n",
    "    moyenne = compute_id_mean(id)\n",
    "    return 0 if proportion_in_interval(id, moyenne, 1e9) < hyperparameters['seuil_'+suffix] else 1\n",
    "\n",
    "# 7eme caracteristique: sujet sain si la écart-type de l'électrocardiogramme est inférieur à un seuil.\n",
    "def calcul_caracteristique7A(id: int, hyperparameters: dict, suffix: str) -> int:\n",
    "    return 0 if compute_id_std_dev(id) < hyperparameters['seuil_'+suffix] else 1\n",
    "\n",
    "# caracteristique 7B: sujet sain si l'écart type autour de la médiane de l'électrocardiogramme est inférieur à un seuil.\n",
    "def calcul_caracteristique7B(id: int, hyperparameters: dict, suffix: str) -> int:\n",
    "    return 0 if compute_id_std_median(id) < hyperparameters['seuil_'+suffix] else 1\n",
    "\n",
    "# 8eme caracteristique: sujet sain si le pourcentage de points dans l'intervalle [ k1 * moyenne, (1+k2) * moyenne] est supérieur à un seuil.\n",
    "def calcul_caracteristique8(id: int, hyperparameters: dict, suffix: str) -> int:\n",
    "    k1 = hyperparameters['k1_'+suffix]\n",
    "    k2 = hyperparameters['k2_'+suffix]\n",
    "    moyenne = compute_id_mean(id)\n",
    "    return 0 if proportion_in_interval(id, k1*moyenne, (1+k2)*moyenne) > hyperparameters['seuil_'+suffix] else 1\n",
    "\n",
    "# caracteristique 9: sujet sain si le pourcentage de points dans l'intervalle [ 0, k] est inférieur à un seuil.\n",
    "def calcul_caracteristique9(id: int, hyperparameters: dict, suffix: str) -> int:\n",
    "    k = hyperparameters['k_'+suffix]\n",
    "    return 0 if proportion_in_interval(id, 0, k) < hyperparameters['seuil_'+suffix] else 1\n",
    "   \n",
    "def calcul_caracteristique13(id: int, hyperparameters: dict, suffix: str) -> int:\n",
    "    k = hyperparameters['k_'+suffix]\n",
    "    return 0 if count_crossing_in_5minutes(id, k) > hyperparameters['seuil_'+suffix] else 1\n",
    "\n",
    "def calcul_caracteristique14A(id: int, hyperparameters: dict, suffix: str) -> int:\n",
    "    return 0 if count_crossing_in_5minutes(id, compute_id_mean(id)) > hyperparameters['seuil_'+suffix] else 1\n",
    "\n",
    "def calcul_caracteristique14B(id: int, hyperparameters: dict, suffix: str) -> int:\n",
    "    return 0 if count_crossing_in_5minutes(id, compute_id_median(id)) > hyperparameters['seuil_'+suffix] else 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6398b39",
   "metadata": {},
   "source": [
    "# PRIVE: Hyperparameters Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04040a0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from typing import List\n",
    "import math\n",
    "from hyperopt import fmin, tpe, space_eval, hp, Trials, rand as hyperopt_rand\n",
    "import hashlib\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "current_lowest_error = None\n",
    "stats_hpo = dict()\n",
    "last_time_display_stats_hpo = time.time()\n",
    "\n",
    "def compute_error(TP: int, TN: int, FP: int, FN: int):\n",
    "    return (compute_error_target0(TP,TN,FP,FN)+compute_error_target1(TP,TN,FP,FN))/2\n",
    "\n",
    "def compute_f1_score(TP: int, TN: int, FP: int, FN: int):\n",
    "    return (2*TP)/(2*TP+FP+FN)\n",
    "        \n",
    "def compute_error_target0(TP: int, TN: int, FP: int, FN: int):\n",
    "    return 1.0-TN/(1*TN+FP)\n",
    "\n",
    "def compute_error_target1(TP: int, TN: int, FP: int, FN: int):\n",
    "    return 1.0-TP/(1*TP+FN)\n",
    "        \n",
    "def compute_matrice_de_confusion(id_to_predictions, id_to_target) -> (int, int, int,int):\n",
    "        TP = 0\n",
    "        TN = 0\n",
    "        FP = 0\n",
    "        FN = 0\n",
    "        for id, data in id_to_predictions.items():\n",
    "            target = id_to_target[id]\n",
    "            prediction = id_to_predictions[id]\n",
    "            if prediction == target: # bonne prediction\n",
    "                if target == 1:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    TN += 1\n",
    "            else: # erreur dans la prediciton\n",
    "                if prediction == 1:\n",
    "                    FP += 1\n",
    "                else:\n",
    "                    FN += 1\n",
    "        return (TP,TN,FP,FN)\n",
    "\n",
    "def compute_single_prediction_single_caracteristique(id: str, hyperparameters: dict, caracteristique: str) -> int:  \n",
    "    if caracteristique[-1:] == 'i':\n",
    "        # we compute the complement of caracteristique 'caracteristique[:-1]'\n",
    "        # ex: caracteristique '10i' will compute the complement of caracteristique '10'\n",
    "        return 1-globals()['calcul_caracteristique'+caracteristique[:-1]](id, hyperparameters, caracteristique)\n",
    "    return globals()['calcul_caracteristique'+caracteristique](id, hyperparameters, caracteristique)\n",
    "\n",
    "def compute_single_prediction(id: str, hyperparameters: dict) -> int:  \n",
    "    valeurs_caracteristiques_a_utiliser = []\n",
    "    for c in hyperparameters['caracteristiques_a_utiliser'].split('+'):\n",
    "        valeurs_caracteristiques_a_utiliser.append(compute_single_prediction_single_caracteristique(id, hyperparameters, c))\n",
    "    if not all_elements_same(valeurs_caracteristiques_a_utiliser):\n",
    "        return hyperparameters['label_si_resultats_differents']\n",
    "    return valeurs_caracteristiques_a_utiliser[0]\n",
    "    \n",
    "def all_elements_same(data):\n",
    "    first_element = data[0]\n",
    "    return all(element == first_element for element in data)\n",
    "\n",
    "def compute_toutes_les_predictions(hyperparameters: dict) -> dict:\n",
    "    id_to_predictions = dict()\n",
    "    for id in id_to_data.keys():\n",
    "        id_to_predictions[id] = compute_single_prediction(id, hyperparameters)\n",
    "    return id_to_predictions\n",
    "    \n",
    "def train(hyperparameters: dict, verbose: bool) -> dict:\n",
    "    id_to_predictions = compute_toutes_les_predictions(hyperparameters)\n",
    "    (TP,TN,FP,FN) = compute_matrice_de_confusion(id_to_predictions, id_to_target)\n",
    "    metrics = dict()\n",
    "    metrics['TP'] = TP\n",
    "    metrics['TN'] = TN\n",
    "    metrics['FP'] = FP\n",
    "    metrics['FN'] = FN\n",
    "    metrics['error_target0'] = compute_error_target0(TP,TN,FP,FN)\n",
    "    metrics['error_target1'] = compute_error_target1(TP,TN,FP,FN)\n",
    "    current_error = compute_error(TP,TN,FP,FN)\n",
    "    metrics['erreur'] = current_error\n",
    "    update_stats_hpo(current_error, hyperparameters)\n",
    "    global last_time_display_stats_hpo\n",
    "    if (time.time()-last_time_display_stats_hpo)>600:\n",
    "        save_stats_hpo(False)\n",
    "        last_time_display_stats_hpo = time.time()\n",
    "    global current_lowest_error\n",
    "    if not current_lowest_error or current_error<current_lowest_error:\n",
    "        current_lowest_error = current_error\n",
    "        if verbose:\n",
    "            print(f\"new lowest error {round(current_error,4)} for hyperparameters {[c for c in hyperparameters.items() if c[1] is not None]}\")\n",
    "        save_model(hyperparameters, metrics)\n",
    "        save_stats_hpo(False)\n",
    "    return metrics\n",
    "\n",
    "    \n",
    "def update_stats_hpo(error:float, hyperparameters: dict) -> None:\n",
    "    for hpo_key, hpo_value in hyperparameters.items():\n",
    "        if hpo_value is None:\n",
    "            continue\n",
    "        if hpo_key not in stats_hpo:\n",
    "            stats_hpo[hpo_key] = dict()\n",
    "        if hpo_value not in stats_hpo[hpo_key]:\n",
    "            stats_hpo[hpo_key][hpo_value] = [0,0]\n",
    "        stats_hpo[hpo_key][hpo_value][0] += 1\n",
    "        stats_hpo[hpo_key][hpo_value][1] += error\n",
    "\n",
    "    \n",
    "# the objective used for Hyperparameters Optimization (HPO)\n",
    "# it is the function to minimize\n",
    "def objective(sample_from_search_space):\n",
    "    hyperparameters = fix_hyperparameters(sample_from_search_space)\n",
    "    model_name = get_model_name(hyperparameters)\n",
    "    if model_name in already_processed_model_names_with_hpo:\n",
    "        metrics = already_processed_model_names_with_hpo[model_name]\n",
    "    else:\n",
    "        metrics = train(hyperparameters, True)\n",
    "        already_processed_model_names_with_hpo[model_name] = metrics\n",
    "    # we want to minimize this mettric ('erreur')\n",
    "    return metrics['erreur']\n",
    "\n",
    "hpo_session_id = str(int(100*time.time()))\n",
    "\n",
    "def save_stats_hpo(display: bool):\n",
    "    res = stats_hpo_to_str()\n",
    "    try:\n",
    "        path = os.path.join(directory, 'hpo_'+hpo_session_id+\".txt\")\n",
    "        with open(path, 'w') as f:\n",
    "            f.write(res)\n",
    "    except Exception as e:\n",
    "        print(f'failed to save hp')\n",
    "    if display:\n",
    "        print(res)\n",
    "\n",
    "# path to the last model saved\n",
    "last_path_for_save_model = None\n",
    "        \n",
    "def save_model(hyperparameters: dict, metrics: dict) -> None:\n",
    "    global last_path_for_save_model\n",
    "    try:\n",
    "        erreur = metrics['erreur']\n",
    "        path = os.path.join(directory, 'hpo_'+hpo_session_id+'_'+hyperparameters['caracteristiques_a_utiliser']+'_'+str(erreur)+\".txt\")\n",
    "        with open(path, 'w') as f:\n",
    "            text = hyperparameters_to_str(hyperparameters)\n",
    "            for m, v in metrics.items():\n",
    "                text += f'\\n#{m}={v}'\n",
    "            f.write(text)\n",
    "        try:\n",
    "            if last_path_for_save_model and os.path.isfile(last_path_for_save_model):\n",
    "                os.remove(last_path_for_save_model)\n",
    "        except Exception as e:\n",
    "            print(f'failed to delete file {last_path_for_save_model}: {e}')\n",
    "        last_path_for_save_model = path\n",
    "    except Exception as e:\n",
    "        print(f'failed to save hp: {e}')\n",
    "    \n",
    "def stats_hpo_to_str() -> str:\n",
    "    max_intervals = 10\n",
    "    result = \"\"\n",
    "    for hpo_key, hpo_key_stats in stats_hpo.items():\n",
    "        result += f\"stats for key '{hpo_key}':\\n\"\n",
    "        all_values = list(hpo_key_stats.keys())\n",
    "        old_value_to_new_value = dict()\n",
    "        if len(all_values)>max_intervals and (isinstance(all_values[0], int) or isinstance(all_values[0], float)):\n",
    "            min_value = float(min(all_values))\n",
    "            max_value = float(max(all_values))\n",
    "            for v in all_values:\n",
    "                index_interval = int (max_intervals * (float(v-min_value)/(max_value-min_value)))\n",
    "                index_interval = min(index_interval, max_intervals-1)\n",
    "                min_value_interval = min_value+index_interval* (max_value-min_value)/max_intervals\n",
    "                max_value_interval = min_value_interval+ (max_value-min_value)/max_intervals\n",
    "                new_key = f'[{round(min_value_interval,2)}, {round(max_value_interval,2)}]'\n",
    "                if new_key not in old_value_to_new_value:\n",
    "                    old_value_to_new_value[new_key] = [0,0]\n",
    "                old_value_to_new_value[new_key][0] += hpo_key_stats[v][0]\n",
    "                old_value_to_new_value[new_key][1] += hpo_key_stats[v][1]\n",
    "        else:\n",
    "            for v in all_values:\n",
    "                old_value_to_new_value[v] = hpo_key_stats[v]     \n",
    "        \n",
    "        for value, value_stats in sorted(old_value_to_new_value.items(), key=lambda item: item[1][1]/item[1][0], reverse=True):\n",
    "            count = value_stats[0]\n",
    "            avg_error = value_stats[1]/count\n",
    "            result += f'\\t{value} : {avg_error} ({count} samples)\\n'\n",
    "    return result\n",
    "        \n",
    "def extract_caracteristique_id(key: str):\n",
    "    if key == 'caracteristiques_a_utiliser' or key == 'label_si_resultats_differents':\n",
    "        return None\n",
    "    splitted = key.split('_')\n",
    "    if len(splitted)>=2 and len(splitted[-1]) >=1 and splitted[-1][0].isdigit():\n",
    "        return splitted[-1]\n",
    "    return None\n",
    "\n",
    "# When conducting an HPO search, some hyperparameters may exhibit inconsistent values.\n",
    "# This method aims to address those inconsistencies.\n",
    "def fix_hyperparameters(hyperparameters: dict) -> dict :\n",
    "    res = dict(hyperparameters)\n",
    "    for key in list(res.keys()):\n",
    "        caracteristique_id = extract_caracteristique_id(key)\n",
    "        if caracteristique_id and caracteristique_id not in res['caracteristiques_a_utiliser'].split('+'):\n",
    "            del res[key]\n",
    "    if '+' not in res['caracteristiques_a_utiliser']:\n",
    "        res['label_si_resultats_differents'] = None\n",
    "    return res\n",
    "\n",
    "\n",
    "# Transform the dictionary of hyperparameters 'hyperparameters' into string.\n",
    "def hyperparameters_to_str(hyperparameters: dict) -> str:\n",
    "    sorted_hyperparameters = sorted (hyperparameters.items())\n",
    "    return \"\\n\".join([hyperparameter_name+\" = \"+str(hyperparameter_value) for (hyperparameter_name,hyperparameter_value) in sorted_hyperparameters if hyperparameter_value is not None])\n",
    "\n",
    "def get_model_name(hyperparameters: dict) -> str:\n",
    "    file_content = hyperparameters_to_str(hyperparameters)\n",
    "    return compute_hash(file_content, 10)\n",
    "\n",
    "def compute_hash(input_string, max_length):\n",
    "    # Calculate MD5 hash of the input string\n",
    "    md5_hash = hashlib.md5(input_string.encode('ascii')).hexdigest().upper()\n",
    "    # Return the hash truncated to the max_length\n",
    "    return md5_hash[:max_length]\n",
    "\n",
    "def launch_hpo_for_transformer_model(max_evals: int):\n",
    "    seed = random.randint(0, 100000)\n",
    "    print(f'using seed: {seed}')\n",
    "    rstate = np.random.default_rng(seed)\n",
    "    best_indexes = fmin(\n",
    "        fn=objective,  # \"Loss\" function to minimize\n",
    "        space=search_space,  # Hyperparameter space\n",
    "        algo=hyperopt_rand.suggest, #Random Search\n",
    "        #algo=tpe.suggest,  # Tree-structured Parzen Estimator (TPE)\n",
    "        max_evals=max_evals,  # Perform 'max_evals' trials\n",
    "        max_queue_len = 10,\n",
    "        rstate =rstate,\n",
    "    )\n",
    "\n",
    "    # Get the best parameters\n",
    "    best  = space_eval(search_space, best_indexes)\n",
    "    print(f\"Found minimum after {max_evals} trials:\")\n",
    "    print([c for c in best.items() if c[1] is not None])\n",
    "    return best\n",
    "\n",
    "\n",
    "\n",
    "def float_range(x1: float, x2: float, count:int = 100) -> List[float]:\n",
    "    epsilon = (x2-x1)/count\n",
    "    # Generate the range of float values with the specified step\n",
    "    return list(np.arange(x1, x2, epsilon))\n",
    "\n",
    "def int_range(x:int, y:int, count:int = 100) -> List[int]:\n",
    "    epsilon = int ((y+1-x)/count )\n",
    "    epsilon = max(epsilon, 1)\n",
    "    return list(range(x, y+1,epsilon))\n",
    "\n",
    "\n",
    "\n",
    "search_space = {\n",
    "\n",
    "    # 1ere caracteristique version 1A : sujet sain si le pourcentage de points dans un intervalle donné est supérieur à un seuil (avec ajustement à la moyenne).\n",
    "    'min_value_1A': hp.choice('min_value_1A', int_range(80,120)), # 95 104 93\n",
    "    'range_1A': hp.choice('range_1A', int_range(50,150)), # 125 , 115 , 85  89\n",
    "    'seuil_1A': hp.choice('seuil_1A', float_range(0.9, 1.0)), # 0.95 0.96 0.97\n",
    "\n",
    "    # complément de la caractéristique 1A: sujet sain si le pourcentage de points dans un intervalle donné est inférieur à un seuil (avec ajustement à la moyenne).\n",
    "    'min_value_1Ai': hp.choice('min_value_1Ai', int_range(15,50)),  # 35 , 20, 22 20\n",
    "    'range_1Ai': hp.choice('range_1Ai', int_range(50,100)), # 65 ,64 87 72\n",
    "    'seuil_1Ai': hp.choice('seuil_1Ai', float_range(0.0, 0.1)), # 0.04 , 0.03 0.01  0.053 0.03\n",
    "\n",
    "    # 1ere caracteristique version 1B : sujet sain si le pourcentage de points dans un intervalle donné est supérieur à un seuil (sans ajustement à la moyenne).\n",
    "    'min_value_1B': hp.choice('min_value_1B', int_range(80,120)), # 93 97\n",
    "    'range_1B': hp.choice('range_1B', int_range(20,100)), # 72 61\n",
    "    'seuil_1B': hp.choice('seuil_1B', float_range(0.8, 1.0, 200)), # 0.906 0.882\n",
    "\n",
    "    # complément de la caractéristique 1B: sujet sain si le pourcentage de points dans un intervalle donné est inférieur à un seuil (sans ajustement à la moyenne).\n",
    "    'min_value_1Bi': hp.choice('min_value_1Bi', int_range(10,100)), # 14  60\n",
    "    'range_1Bi': hp.choice('range_1Bi', int_range(20,100)), # 70 30\n",
    "    'seuil_1Bi': hp.choice('seuil_1Bi', float_range(0.0, 0.1)), # 0.03 0.024\n",
    "\n",
    "    # 3eme caracteristique: sujet sain si l'étendue de l'électrocardiogramme est inférieur à un seuil.\n",
    "    'seuil_3': hp.choice('seuil_3', float_range(50,250, 1000)), # 124\n",
    "\n",
    "    # caracteristique 4A: sujet sain si le pourcentage de points autour de la moyenne est supérieur à un seuil.\n",
    "    'range_4A': hp.choice('range_4A', float_range(10,50)), # 43 44\n",
    "    'seuil_4A': hp.choice('seuil_4A', float_range(0.90, 0.99,1000)), # 0.96 0.97\n",
    "\n",
    "    # caracteristique 4B: sujet sain si le pourcentage de points autour de la médiane est supérieur à un seuil.\n",
    "    'range_4B': hp.choice('range_4B', float_range(10,50)), # 37  25 43\n",
    "    'seuil_4B': hp.choice('seuil_4B', float_range(0.90, 0.99,1000)), # 0.96\n",
    "\n",
    "    # caracteristique 5A: sujet sain si la moyenne de l'électrocardiogramme est dans l'intervalle [k1, k2]\n",
    "    #'min_value_5A': hp.choice('min_value_5A', list(range(122-40,122+40+1,1))),\n",
    "    #'seuil_5A': hp.choice('seuil_5A', list(range(9-6,9+6+1,1))),\n",
    "    'min_value_5A': hp.choice('min_value_5A', int_range(100,170)), # 124 142\n",
    "    'range_5A': hp.choice('range_5A', int_range(0,30)), # 11 14\n",
    "\n",
    "    # complément de la caractéristique 5A\n",
    "    'min_value_5Ai': hp.choice('min_value_5Ai', int_range(100,170)), # 131 133\n",
    "    'range_5Ai': hp.choice('range_5Ai', int_range(0,30)), #9 11\n",
    "\n",
    "    # caracteristique 5B: sujet sain si la moyenne de l'électrocardiogramme est dans l'intervalle [k1, k2]\n",
    "    'min_value_5B': hp.choice('min_value_5B', int_range(50,170)), # 110\n",
    "    'range_5B': hp.choice('range_5B', int_range(0,50)), # 28\n",
    "   \n",
    "    # caracteristique 6: sujet sain si le % de points au dessus de la moyenne de l'électrocardiogramme est inférieur à un seuil.\n",
    "    #'seuil_6': hp.choice('seuil_6', [(i * 0.01) for i in range(61-30, 61+30+1,1)]),\n",
    "    'seuil_6': hp.choice('seuil_6', float_range(0.0, 1.0, 1000)), # 0.629\n",
    "\n",
    "    # caracteristique 7A: sujet sain si l'écart type de l'électrocardiogramme est inférieur à un seuil.\n",
    "    'seuil_7A': hp.choice('seuil_7A', float_range(18.0, 22.0, 1000)), # 19.25 19.43\n",
    "    \n",
    "    # caracteristique 7B: sujet sain si l'écart type autour de la médiane de l'électrocardiogramme est inférieur à un seuil.\n",
    "    'seuil_7B': hp.choice('seuil_7B', float_range(18.0, 22.0, 1000)), # 19.636  19.615\n",
    "    \n",
    "    # 8eme caracteristique: sujet sain si le pourcentage de points dans l'intervalle [ k1 * moyenne, (1+k2) * moyenne] est supérieur à un seuil.\n",
    "    'k1_8': hp.choice('k1_8', float_range(0.5, 0.9)), # 0.66  0.72  0.71 \n",
    "    'k2_8': hp.choice('k2_8', float_range(0.08, 0.2)),  # 0.13 0.14 0.1\n",
    "    'seuil_8': hp.choice('seuil_8', float_range(0.8, 1.0)), #0.87 0.96 0.84\n",
    "\n",
    "    # caracteristique 9: sujet sain si le pourcentage de points dans l'intervalle [ 0, k] est inférieur à un seuil.\n",
    "    'k_9': hp.choice('k_9', float_range(50, 150,1000)), # 86\n",
    "    'seuil_9': hp.choice('seuil_9', float_range(0.0, 0.1)  ), # 0.03 0.017\n",
    "\n",
    "    # complément de la caractéristique 9\n",
    "    'k_9i': hp.choice('k_9i', float_range(150,200)), # 156  151\n",
    "    'seuil_9i': hp.choice('seuil_9i', float_range(0.8, 1.0)), # 0.94 0.885\n",
    "\n",
    "    # caracteristique 13: sujet sain si le nombre de passage par une valeur 'k' en 5 minutes est > à un seuil.\n",
    "    'k_13': hp.choice('k_13', int_range(10, 180)),  # 139 140\n",
    "    'seuil_13': hp.choice('seuil_13', float_range(0, 50, 100)),\n",
    "\n",
    "    # complément de la caractéristique 13\n",
    "    'k_13i': hp.choice('k_13i', int_range(50, 90)),  #67 73 72\n",
    "    'seuil_13i': hp.choice('seuil_13i', float_range(0, 50, 500)),\n",
    "\n",
    "    # caracteristique 14A: sujet sain si le nombre de passage par la moyenne en 5minutes est > à un seuil.\n",
    "    'seuil_14A': hp.choice('seuil_14A', float_range(15, 40, 1000)),\n",
    "    \n",
    "    # caracteristique 14B: sujet sain si le nombre de passage par la médiane en 5 minutes  est > à un seuil.\n",
    "    'seuil_14B': hp.choice('seuil_14B', float_range(15, 40, 1000)),\n",
    "    \n",
    "    'caracteristiques_a_utiliser': hp.choice('caracteristiques_a_utiliser', ['14A+7A']),\n",
    "    'label_si_resultats_differents': hp.choice('label_si_resultats_differents', [0, 1]),\n",
    "}\n",
    "\n",
    "\n",
    "if len(sys.argv) >=2 and str.isdigit(sys.argv[1][0]):\n",
    "    caracteristiques_a_utiliser = sys.argv[1].split(',')\n",
    "    print(f'caracteristiques_a_utiliser will be set to {caracteristiques_a_utiliser}')\n",
    "    search_space['caracteristiques_a_utiliser'] =  hp.choice('caracteristiques_a_utiliser', caracteristiques_a_utiliser)\n",
    "\n",
    "\n",
    "max_evals = 1000\n",
    "if len(sys.argv) >=3 and str.isdigit(sys.argv[2]):\n",
    "    print(f'max_evals will be set to {sys.argv[2]}')\n",
    "    max_evals = int(sys.argv[2])\n",
    "print(f'max_evals value is {max_evals}')\n",
    "\n",
    "already_processed_model_names_with_hpo = dict()\n",
    "start_time = time.time()\n",
    "# Uncomment following line to enable HPO\n",
    "#best = launch_hpo_for_transformer_model(max_evals)\n",
    "print(f'hpo took {round(time.time()-start_time,2)}s')\n",
    "save_stats_hpo(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c810a07e",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">\n",
    "<span style=\"font-size: 48px;\">1ère partie</span>\n",
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35817cf8",
   "metadata": {},
   "source": [
    "# Approche par le nombre de passages par la moyenne\n",
    "## le nombre de passage par la moyenne est plus faible pour les sujets malades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c13cbc0",
   "metadata": {},
   "source": [
    "## On demande à l'étudiant de compter le nombre de passages par la moyenne pour des sujets sains et pour des sujets malades en 5 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad18a78",
   "metadata": {},
   "source": [
    "## PRIVE: TODO: Exemple d'électrocardiogrammes de sujets sains pour lesquels on peut demander de compter le nombre de passages par la moyenne "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e84fab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_electrocardiogram(53, 105+3, 5, min_y_value=125, max_y_value=165)\n",
    "display_electrocardiogram(53, 156, 5, min_y_value=110, max_y_value=160)\n",
    "display_electrocardiogram(54, 0, 5, min_y_value=120, max_y_value=150)\n",
    "display_electrocardiogram(56, 60+30, 5, min_y_value=125, max_y_value=155)\n",
    "display_electrocardiogram(56, 56, 5, min_y_value=115, max_y_value=155)\n",
    "display_electrocardiogram(75, 11, 5, min_y_value=100, max_y_value=135)\n",
    "display_electrocardiogram(75, 27, 5, min_y_value=85, max_y_value=130)\n",
    "display_electrocardiogram(75, 55, 5, min_y_value=90, max_y_value=125)\n",
    "display_electrocardiogram(76, 43+39, 5, min_y_value=115, max_y_value=155)\n",
    "display_electrocardiogram(84, 115, 5, min_y_value=120, max_y_value=175)\n",
    "display_electrocardiogram(90, 70, 5, min_y_value=130, max_y_value=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4433c813",
   "metadata": {},
   "source": [
    "## PRIVE: TODO: Exemple d'électrocardiogrammes de sujets malades pour lesquels on peut demander de compter le nombre de passages par la moyenne "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602bd0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_electrocardiogram(46, 10, 5)\n",
    "display_electrocardiogram(46, 87.9, 5)\n",
    "display_electrocardiogram(46, 92.9, 5)\n",
    "display_electrocardiogram(46, 110.5 , 5)\n",
    "display_electrocardiogram(46,235.5 , 5)\n",
    "display_electrocardiogram(70,-120+95.6 , 5)\n",
    "display_electrocardiogram(87, 42, 5)\n",
    "display_electrocardiogram(103, 55.5, 5)\n",
    "display_electrocardiogram(103,-120+44.1 , 5)\n",
    "display_electrocardiogram(123,-120+65 , 5)\n",
    "display_electrocardiogram(123,-120+70 , 5)\n",
    "display_electrocardiogram(150, 17, 5)\n",
    "display_electrocardiogram(224, 12.8, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e92525",
   "metadata": {},
   "source": [
    "# TODO: 1B\n",
    "## Faire constater par l'étudiant que ce nombre de passages par la moyenne est plus important pour les sujets sains que pour les sujets malades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f843946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_stats_nombre_de_passages_par_la_moyenne_en_5_minutes():\n",
    "    count_crossing_target_0 =[]\n",
    "    count_crossing_target_1 =[]\n",
    "    for id in id_to_data.keys():\n",
    "        count_crossing = count_crossing_in_5minutes(id, compute_id_mean(id))\n",
    "        if 0 == id_to_target[id]:\n",
    "            count_crossing_target_0.append(count_crossing)\n",
    "        else:\n",
    "            count_crossing_target_1.append(count_crossing)\n",
    "    print(f'Nombre de passages par la moyenne en 5 minutes:')\n",
    "    print(f'\\tMoyenne pour les sujets sains = {round(np.mean(count_crossing_target_0),2)}')\n",
    "    print(f'\\tMoyenne pour les sujets malades = {round(np.mean(count_crossing_target_1),2)}')\n",
    "display_stats_nombre_de_passages_par_la_moyenne_en_5_minutes()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d72f86c",
   "metadata": {},
   "source": [
    "# Affichage de la qualité de  l'outil en fonction de la valeur de la caractéristique: nombre de passages par la moyenne 5 minutes.\n",
    "## Au dessus de ce seuil, on considère que le sujet est sain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296c083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import make_interp_spline\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "valeurs_caracteristique = []\n",
    "erreur_caracteristique = []\n",
    "for seuil_nombre_de_passages_par_la_moyenne_en_5_minutes in list(np.arange(0, 50, 0.1)):\n",
    "    config = {'caracteristiques_a_utiliser': '14A', 'seuil_14A': seuil_nombre_de_passages_par_la_moyenne_en_5_minutes}\n",
    "    erreur = train(config, False)['erreur']\n",
    "    valeurs_caracteristique.append(seuil_nombre_de_passages_par_la_moyenne_en_5_minutes)\n",
    "    erreur_caracteristique.append(erreur)\n",
    "\n",
    "x_dense = np.linspace(min(valeurs_caracteristique), max(valeurs_caracteristique), 500)  # 500 points pour une courbe lisse\n",
    "spline = make_interp_spline(valeurs_caracteristique, erreur_caracteristique)\n",
    "y_dense = spline(x_dense)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(x_dense, y_dense, label='Erreur', color='b')\n",
    "plt.scatter(valeurs_caracteristique, erreur_caracteristique, color='r')\n",
    "plt.gca().tick_params(axis='y', which='major', labelsize=20) \n",
    "#plt.gca().xaxis.set_major_formatter(PercentFormatter(1))\n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "plt.xticks(fontsize=20)\n",
    "plt.xlabel(\"Nombre de passages par la moyenne en 5 minutes\", fontsize=20)\n",
    "plt.ylabel('Erreur', fontsize=20)\n",
    "plt.title(\"Erreur (%) en fonction du nombre de passages en 5 minutes\", fontsize=20)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2d5922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l'étudiant devra remplacer le 10 ci dessous\n",
    "\n",
    "seuil_nombre_de_passages_par_la_moyenne_en_5_minutes = 20\n",
    "\n",
    "config = {'caracteristiques_a_utiliser': '14A', 'seuil_14A': seuil_nombre_de_passages_par_la_moyenne_en_5_minutes, 'label_si_resultats_differents': 1}\n",
    "metrics = train(config, False)\n",
    "print(f\"Erreur obtenue: {round(100*metrics['erreur'],1)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6815e02",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">\n",
    "<span style=\"font-size: 48px;\">2ème partie</span>\n",
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f9685c",
   "metadata": {},
   "source": [
    "# TODO: \n",
    "# Faire constater par l'étudiant que l'écart type de l'électrocardiogramme des sujets malades est en moyenne plus élevé que l'écart type observé pour les sujets sains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b52e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_stats_std_dev():\n",
    "    std_dev_target_0 =[]\n",
    "    srd_dev_target_1 =[]\n",
    "    for id in id_to_data.keys():\n",
    "        std_dev = compute_id_std_dev(id)\n",
    "        if 0 == id_to_target[id]:\n",
    "            std_dev_target_0.append(std_dev)\n",
    "        else:\n",
    "            srd_dev_target_1.append(std_dev)\n",
    "    print(f'Ecart type:')\n",
    "    print(f'\\tMoyenne pour les sujets sains = {round(np.mean(std_dev_target_0),2)}')\n",
    "    print(f'\\tMoyenne pour les sujets malades = {round(np.mean(srd_dev_target_1),2)}')\n",
    "display_stats_std_dev()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1bacdc",
   "metadata": {},
   "source": [
    "# Affichage de la qualité de  l'outil en fonction du seuil d'écart type choisi pour identifier les sujets malades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba74d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "valeurs_caracteristique = []\n",
    "erreur_caracteristique = []\n",
    "for threshold_ecart_type in range(0,30+1,1):\n",
    "    config = {'caracteristiques_a_utiliser': '7A', 'seuil_7A': threshold_ecart_type}\n",
    "    erreur = train(config, False)['erreur']\n",
    "    valeurs_caracteristique.append(threshold_ecart_type)\n",
    "    erreur_caracteristique.append(erreur)\n",
    "    #print(f\"threshold_ecart_type={threshold_ecart_type} => Erreur={round(100*erreur,1)}%\")\n",
    "\n",
    "x_dense = np.linspace(min(valeurs_caracteristique), max(valeurs_caracteristique), 500)  # 500 points pour une courbe lisse\n",
    "spline = make_interp_spline(valeurs_caracteristique, erreur_caracteristique)\n",
    "y_dense = spline(x_dense)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(x_dense, y_dense, label='Erreur', color='b')\n",
    "plt.scatter(valeurs_caracteristique, erreur_caracteristique, color='r')\n",
    "plt.gca().tick_params(axis='y', which='major', labelsize=20) \n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "plt.xticks(fontsize=20)\n",
    "plt.xlabel(\"Ecart type de l'électrocardiogramme\", fontsize=20)\n",
    "plt.ylabel('Erreur', fontsize=20)\n",
    "plt.title(\"Erreur en fonction du seuil de l'écart type de l'électrocardiogramme\", fontsize=20)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e16f96a",
   "metadata": {},
   "source": [
    "# On demande à l'étudiant de choisir le seuil pour l'écart type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fedb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l'étudiant devra remplacer le 10 ci dessous\n",
    "seuil_ecart_type = 10\n",
    "\n",
    "config = {'caracteristiques_a_utiliser': '7A', 'seuil_7A': seuil_ecart_type}\n",
    "metrics = train(config, False)\n",
    "print(f\"Erreur obtenue: {round(100*metrics['erreur'],1)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fe9696",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">\n",
    "<span style=\"font-size: 48px;\">3ème partie</span>\n",
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99169c8",
   "metadata": {},
   "source": [
    "# On combine les 2 caractéristiques précédentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e460a90",
   "metadata": {},
   "source": [
    "# TODO: affichage d'un graphique montrant l'évolution de l'erreur en fonction de ces 2 caractéristiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8772350",
   "metadata": {},
   "source": [
    "# On demande à l'étudiant de choisir la valeur de ces 2 caractéristiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddd8371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l'étudiant devra remplacer les 2 valeurs ci dessous\n",
    "\n",
    "seuil_ecart_type = 10\n",
    "seuil_nombre_de_passages_par_la_moyenne_en_5_minutes = 10\n",
    "\n",
    "config = {'caracteristiques_a_utiliser': '7A+14A', 'seuil_7A': seuil_ecart_type, 'seuil_14A': seuil_nombre_de_passages_par_la_moyenne_en_5_minutes,'label_si_resultats_differents': 1}\n",
    "metrics = train(config, False)\n",
    "print(f\"Erreur obtenue: {round(100*metrics['erreur'],1)}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
