{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20fab4cd",
   "metadata": {},
   "source": [
    "# Le but de ce notebook est d'identifier des caractéristiques très simples permettant d'analyser des battements de coeur de foetus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e01dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install hyperopt\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# permet de charger les fichiers matlab (*.mat)\n",
    "from scipy.io import loadmat\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from typing import List,Set,Tuple,Dict\n",
    "\n",
    "# le répertoire de travail\n",
    "directory = os.path.abspath('')\n",
    "\n",
    "# répertoire où se trouvent toutes les données associés à ce challenge\n",
    "data_directory = os.path.join(directory, 'Data')\n",
    "\n",
    "# fichier CSV contenant les targets (1 / 0)\n",
    "targets_path = os.path.join(data_directory, 'CTG_Challenge_files_GroundTruth.csv')\n",
    "\n",
    "# répertoire où se trouvent les fichiers de données matlab\n",
    "matlab_directory = os.path.join(data_directory, 'ctg_workshop_database')\n",
    "\n",
    "# dans l'électrocardiogramme, nous avons 4 mesures par seconde\n",
    "# chaque mesure correspondent à au nombre de battements de coeurs par minute\n",
    "elements_en_1s = 4\n",
    "elements_en_1minute = int(elements_en_1s*60)\n",
    "elements_en_5minutes = 5*elements_en_1minute\n",
    "elements_en_30minutes = 30*elements_en_1minute\n",
    "elements_en_1heure = 60*elements_en_1minute\n",
    "\n",
    "# retourne tous les fichiers matlab présents dans le repertoire 'path'\n",
    "def all_mat_files_in_directory(path: str):\n",
    "    return [os.path.join(path,f) for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith('.mat')]\n",
    "\n",
    "# calcule la moyenne de la séquence ''fhr' en ignorant les NaN\n",
    "def moyenne(fhr):\n",
    "    return fhr[~np.isnan(fhr)].mean()\n",
    "\n",
    "# calcule la std dev de la séquence ''fhr' en ignorant les NaN\n",
    "def ecart_type(fhr):\n",
    "    return fhr[~np.isnan(fhr)].std()\n",
    "\n",
    "# calcul des 3 quartiles Q1 , Q2 (=mediane), Q3 (en ignorant les NaN)\n",
    "def compute_quartiles_Q1_Q2_Q3(fhr) -> Tuple[float,float,float]:\n",
    "    # Remove NaN values\n",
    "    cleaned_data = fhr[~np.isnan(fhr)]\n",
    "    Q1 = np.percentile(cleaned_data, 25)\n",
    "    Q2 = np.percentile(cleaned_data, 50)  # This is the median\n",
    "    Q3 = np.percentile(cleaned_data, 75)\n",
    "    return Q1,Q2,Q3\n",
    "\n",
    "# nombre d elements NaN dans la séquence 'fhr'\n",
    "def nan_count(fhr):\n",
    "    return np.count_nonzero(np.isnan(fhr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7142cf8",
   "metadata": {},
   "source": [
    "# PRIVE: Chargement des données d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d009cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chemin vers tous les fichiers matlab de la base d'entraînement\n",
    "id_to_path = dict()\n",
    "for filename in all_mat_files_in_directory(matlab_directory):\n",
    "    filename_without_extension = os.path.splitext(os.path.basename(filename))[0]    \n",
    "    id = int(filename_without_extension.lstrip('0'))\n",
    "    id_to_path[id] = filename\n",
    "\n",
    "# on charge les targets associés à chaque fichier d'entraînement\n",
    "targets_df = pd.read_csv(targets_path)\n",
    "id_to_target = dict()\n",
    "for _, row in targets_df.iterrows():\n",
    "    id_to_target[row['ChallengeID']] = row['TrueOutcome']\n",
    "\n",
    "# lecture des battements de coeurs des foetus\n",
    "id_to_fhr = dict()\n",
    "all_lengths = []\n",
    "for id, path in id_to_path.items():\n",
    "    matlab_file = loadmat(path)\n",
    "    id_to_fhr[id] = matlab_file['fhr'].flatten()\n",
    "    # on ne garde que la dernière heure #//?D\n",
    "    id_to_fhr[id] = id_to_fhr[id][-60*4*60:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d15ddac",
   "metadata": {},
   "source": [
    "# PRIVE: Calcul de statistiques sur ces données d'entraînement\n",
    "## (pour faciliter la recherche des caractéristiques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a19a106",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "targets = []\n",
    "moyenne_full = []\n",
    "ecart_type_full = []\n",
    "count_full = []\n",
    "nan_count_full = []\n",
    "Q1_full = []\n",
    "Q2_full = []\n",
    "Q3_full = []\n",
    "interquartile_range_full = []\n",
    "\n",
    "moyenne_derniere_heure = []\n",
    "ecart_type_derniere_heure = []\n",
    "count_derniere_heure = []\n",
    "nan_count_derniere_heure = []\n",
    "Q1_derniere_heure = []\n",
    "Q2_derniere_heure = []\n",
    "Q3_derniere_heure = []\n",
    "interquartile_range_derniere_heure = []\n",
    "\n",
    "for id in list(id_to_path.keys()):\n",
    "    ids.append(id)\n",
    "    targets.append(id_to_target[id])\n",
    "    \n",
    "    fhr_full = id_to_fhr[id]\n",
    "    \n",
    "    moyenne_full.append(moyenne(fhr_full))\n",
    "    ecart_type_full.append(ecart_type(fhr_full)) \n",
    "    count_full.append(fhr_full.size)\n",
    "    nan_count_full.append(nan_count(fhr_full))\n",
    "    (Q1,Q2,Q3) = compute_quartiles_Q1_Q2_Q3(fhr_full)\n",
    "    Q1_full.append(Q1)\n",
    "    Q2_full.append(Q2)\n",
    "    Q3_full.append(Q3)\n",
    "    interquartile_range_full.append(Q3-Q1)\n",
    "    \n",
    "    fhr_derniere_heure = fhr_full[-elements_en_1heure:]\n",
    "    moyenne_derniere_heure.append(moyenne(fhr_derniere_heure))\n",
    "    ecart_type_derniere_heure.append(ecart_type(fhr_derniere_heure)) \n",
    "    count_derniere_heure.append(fhr_derniere_heure.size)\n",
    "    nan_count_derniere_heure.append(nan_count(fhr_derniere_heure))\n",
    "    (Q1,Q2,Q3) = compute_quartiles_Q1_Q2_Q3(fhr_derniere_heure)\n",
    "    Q1_derniere_heure.append(Q1)\n",
    "    Q2_derniere_heure.append(Q2)\n",
    "    Q3_derniere_heure.append(Q3)\n",
    "    interquartile_range_derniere_heure.append(Q3-Q1)\n",
    "\n",
    "    \n",
    "# Sauvegarde de ces statistiques dans un DataFrame\n",
    "fhr_stats = pd.DataFrame(\n",
    "    {'ids': ids,\n",
    "    'targets': targets,\n",
    "    'moyenne_full' : moyenne_full,\n",
    "    'ecart_type_full' : ecart_type_full,\n",
    "    'count_full' : count_full,\n",
    "    'nan_count_full' : nan_count_full,\n",
    "    'Q1_full' : Q1_full,\n",
    "    'Q2_full' : Q2_full,\n",
    "    'Q3_full' : Q3_full,\n",
    "    'interquartile_range_full' : interquartile_range_full,\n",
    "    'moyenne_derniere_heure' : moyenne_derniere_heure,\n",
    "    'ecart_type_derniere_heure' : ecart_type_derniere_heure,\n",
    "    'count_derniere_heure' : count_derniere_heure,\n",
    "    'nan_count_derniere_heure' : nan_count_derniere_heure,\n",
    "    'Q1_derniere_heure' : Q1_derniere_heure,\n",
    "    'Q2_derniere_heure' : Q2_derniere_heure,\n",
    "    'Q3_derniere_heure' : Q3_derniere_heure,\n",
    "    'interquartile_range_derniere_heure' : interquartile_range_derniere_heure,\n",
    "    })\n",
    "\n",
    "# on sauvegarde ces stats sur le disque\n",
    "fhr_stats.to_csv(os.path.join(directory, 'fhr_stats.csv'), index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1bd514",
   "metadata": {},
   "source": [
    "# PRIVE: méthodes permettant l'affichage d'électrocardiogrammes et d'histogrammes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d1cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "def interpolate_nans(array):\n",
    "    not_nan = ~np.isnan(array)\n",
    "    indices = np.arange(len(array))\n",
    "    interpolated_array = np.copy(array)\n",
    "    interpolated_array[np.isnan(array)] = np.interp(indices[np.isnan(array)], indices[not_nan], array[not_nan])\n",
    "    return interpolated_array\n",
    "\n",
    "def display_electrocardiogram(id: int, start_minut:float, duration_in_minuts: float, display_mean: bool = True, interpolate_missing_values:bool = True, min_y_value: int = None, max_y_value: int = None):\n",
    "    fhr_full = loadmat(id_to_path[id])['fhr'].ravel()\n",
    "    start_idx = int(start_minut*4*60)\n",
    "    if start_idx<0: \n",
    "        start_idx+=len(fhr_full)\n",
    "    start_idx = max(0, start_idx-1)\n",
    "    end_idx = min( start_idx+1+int(duration_in_minuts*4*60) , len(fhr_full) )\n",
    "    \n",
    "    fhr = fhr_full[start_idx:end_idx]\n",
    "    if interpolate_missing_values:\n",
    "        fhr = interpolate_nans(fhr)\n",
    "    \n",
    "    # nombre d'éléments dans l'électrocardiogramme\n",
    "    n = len(fhr)\n",
    "    \n",
    "    # Create an array of time points (assuming each heart rate measurement is taken at regular intervals)\n",
    "    time_in_minuts = np.arange(n)/(60*4)\n",
    "    # Plot the heart rate data\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.plot(time_in_minuts, fhr, linestyle='-', color='black', linewidth=1)\n",
    "    # Formater les ticks pour afficher le temps au format hh:mm\n",
    "    def format_func(time_in_minuts, tick_number):\n",
    "        #time_in_minuts = int(time_in_minuts/(60*4))\n",
    "        hours = int(time_in_minuts) // 60\n",
    "        minutes = int(time_in_minuts) % 60\n",
    "        return f'{hours:02d}:{minutes:02d}'\n",
    "    plt.gca().xaxis.set_major_formatter(ticker.FuncFormatter(format_func))\n",
    "    comment = 'sujet sain' if id_to_target[id] == 0 else 'sujet malade'\n",
    "    \n",
    "    if display_mean:\n",
    "        observed_mean = int(moyenne(fhr_full))\n",
    "        plt.axhline(y=observed_mean, color='red', linewidth=1, linestyle='-', label='Moyenne: '+str(observed_mean))\n",
    "        # Annotate the y-value on the vertical axis\n",
    "        plt.text(x=0, y=observed_mean, s=f'{observed_mean:.0f}', color='red', va='center', ha='right')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Temps (minutes)', fontsize=15)\n",
    "    plt.ylabel('Battements de coeur par minutes', fontsize=15)\n",
    "    plt.title(f\"Electrocardiogramme pour un {comment} ({id})\", fontsize=15)\n",
    "    plt.xlim(0, max(time_in_minuts))\n",
    "    plt.ylim(min_y_value or 60, max_y_value or 180)\n",
    "    # Display grid\n",
    "    plt.grid(True)\n",
    "\n",
    "    if display_mean:\n",
    "        plt.legend()\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def display_histogram(id: int, start_minut:float, duration_in_minuts: float, display_mean: bool = True):\n",
    "    fhr_full = loadmat(id_to_path[id])['fhr'].ravel()\n",
    "    start_idx = int(start_minut*4*60)\n",
    "    if start_idx<0: \n",
    "        start_idx+=len(fhr_full)\n",
    "    start_idx = max(0, start_idx-1)\n",
    "    end_idx = min( start_idx+1+int(duration_in_minuts*4*60) , len(fhr_full) )\n",
    "    data = fhr_full[start_idx:end_idx]\n",
    "    # we discard NaN\n",
    "    data = data[~np.isnan(data)] \n",
    "    plt.figure(figsize=(16, 6))  # Increase the width for better horizontal display\n",
    "    # Plotting the histogram\n",
    "    counts, bins, patches = plt.hist(data, bins=30, edgecolor='black', weights=[100/len(data)]*len(data))\n",
    "    \n",
    "    # Adding title and labels\n",
    "    comment = 'sujet sain' if id_to_target[id] == 0 else 'sujet malade'\n",
    "\n",
    "    plt.title(\"Histogramme\")\n",
    "    plt.xlabel('Nombre de battements de coeur à la minute')\n",
    "    plt.ylabel('Fréquence (%)')\n",
    "\n",
    "    if display_mean:\n",
    "        observed_mean = int(moyenne(fhr_full))\n",
    "        plt.axvline(observed_mean, color='red', linestyle='-', linewidth=2)\n",
    "        plt.text(observed_mean, plt.ylim()[1]*0.9, f'Moyenne: {observed_mean:.2f}', color='red', ha='center')\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def display_electrocardiograms(count:int, start_minut:int, duration_in_minuts: int, label: int, start_id:int = 1, display_mean: bool = True, interpolate_missing_values:bool = True, min_y_value: int = None, max_y_value: int = None):\n",
    "    displayed_count = 0\n",
    "    for idx in range(start_id, start_id+300,1):\n",
    "        id = idx if idx <=300 else idx-300\n",
    "        if id_to_target[id] != label:\n",
    "            continue\n",
    "        display_electrocardiogram(id, start_minut, duration_in_minuts, display_mean=display_mean, interpolate_missing_values=interpolate_missing_values, min_y_value=min_y_value, max_y_value=max_y_value)\n",
    "        display_histogram(id, start_minut, duration_in_minuts, display_mean=display_mean)\n",
    "        displayed_count+= 1\n",
    "        if displayed_count>=count:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5bab3a",
   "metadata": {},
   "source": [
    "# Affichage d'exemples de données pour des sujets sains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91be5329",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_a_afficher = 20\n",
    "start_minut = -60\n",
    "duration_in_minuts = 30\n",
    "label = 0  #0 pour les sujets sains , 1 pour les sujets malades\n",
    "start_id =1 # id du 1er élément à afficher\n",
    "\n",
    "display_electrocardiograms(nombre_a_afficher, start_minut, duration_in_minuts, label, start_id, display_mean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceec7c4c",
   "metadata": {},
   "source": [
    "# Affichage d'exemples de données pour des sujets malades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad19cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_a_afficher = 20\n",
    "start_minut = -60\n",
    "duration_in_minuts = 30\n",
    "label = 1  #0 pour les sujets sains , 1 pour les sujets malades\n",
    "start_id = 1 # id du 1er élément à afficher\n",
    "\n",
    "\n",
    "display_electrocardiograms(nombre_a_afficher, start_minut, duration_in_minuts, label, start_id, display_mean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495f78b8",
   "metadata": {},
   "source": [
    "# PRIVE: Liste des caractéristiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505aa43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "id_to_data = id_to_fhr\n",
    "\n",
    "# calcul de l'écart type\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def compute_id_std_dev(id: int):\n",
    "    return ecart_type(id_to_data[id])\n",
    "\n",
    "# calcul de la variance\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def compute_id_variance(id: int):\n",
    "    std_dev = ecart_type(id_to_data[id])\n",
    "    return std_dev * std_dev\n",
    "    \n",
    "# calcul de l'etendue de la séquence associée à l'id 'id' en ignorant les NaN\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def compute_id_range(id: int):\n",
    "    data = id_to_data[id]\n",
    "    return np.nanmax(data)-np.nanmin(data)\n",
    "   \n",
    "# calcul de la moyenne de la séquence associée à l'id 'id' en ignorant les NaN\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def compute_id_mean(id: int):\n",
    "    return moyenne(id_to_data[id])\n",
    "\n",
    "# calcul des 3 quartiles Q1 , Q2 (=mediane), Q3 de l'id 'id' (en ignorant les NaN)\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def compute_id_quartiles_Q1_Q2_Q3(id: int) -> Tuple[float,float,float]:\n",
    "    return compute_quartiles_Q1_Q2_Q3(id_to_data[id])\n",
    "\n",
    "# calcul de l'écart interquartile (en ignorant les NaN)\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def compute_id_interquartile_range(id: int) -> float:\n",
    "    (Q1,Q2,Q3) = compute_id_quartiles_Q1_Q2_Q3(id)\n",
    "    return Q3-Q1\n",
    "\n",
    "# caracteristique 3: sujet sain si l'étendue est inférieure à un seuil.\n",
    "def calcul_caracteristique3(id: int, hyperparameters: dict, suffix: str) -> int:\n",
    "    return 0 if compute_id_range(id)< hyperparameters['seuil_'+suffix] else 1\n",
    "\n",
    "# caracteristique 7A: sujet sain si l'écart-type est inférieur à un seuil.\n",
    "def calcul_caracteristique7A(id: int, hyperparameters: dict, suffix: str) -> int:\n",
    "    return 0 if compute_id_std_dev(id) < hyperparameters['seuil_'+suffix] else 1\n",
    "\n",
    "# caracteristique 7C: sujet sain si la variance est inférieure à un seuil.\n",
    "def calcul_caracteristique7C(id: int, hyperparameters: dict, suffix: str) -> int:\n",
    "    return 0 if compute_id_variance(id) < hyperparameters['seuil_'+suffix] else 1\n",
    "\n",
    "# caracteristique 15: sujet sain si l'écart interquartile est inférieur à un seuil\n",
    "def calcul_caracteristique15(id: int, hyperparameters: dict, suffix: str) -> int:\n",
    "    return 0 if compute_id_interquartile_range(id) < hyperparameters['seuil_'+suffix] else 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6398b39",
   "metadata": {},
   "source": [
    "# PRIVE: Hyperparameters Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04040a0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import math\n",
    "from hyperopt import fmin, tpe, space_eval, hp, Trials, rand as hyperopt_rand\n",
    "import hashlib\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "current_lowest_error = None\n",
    "stats_hpo = dict()\n",
    "last_time_display_stats_hpo = time.time()\n",
    "\n",
    "def compute_error(TP: int, TN: int, FP: int, FN: int):\n",
    "    return (compute_error_target0(TP,TN,FP,FN)+compute_error_target1(TP,TN,FP,FN))/2\n",
    "\n",
    "def compute_f1_score(TP: int, TN: int, FP: int, FN: int):\n",
    "    return (2*TP)/(2*TP+FP+FN)\n",
    "        \n",
    "def compute_error_target0(TP: int, TN: int, FP: int, FN: int):\n",
    "    return 1.0-TN/(1*TN+FP)\n",
    "\n",
    "def compute_error_target1(TP: int, TN: int, FP: int, FN: int):\n",
    "    return 1.0-TP/(1*TP+FN)\n",
    "        \n",
    "def compute_matrice_de_confusion(id_to_predictions, id_to_target) -> (int, int, int,int):\n",
    "        TP = 0\n",
    "        TN = 0\n",
    "        FP = 0\n",
    "        FN = 0\n",
    "        for id, data in id_to_predictions.items():\n",
    "            target = id_to_target[id]\n",
    "            prediction = id_to_predictions[id]\n",
    "            if prediction == target: # bonne prediction\n",
    "                if target == 1:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    TN += 1\n",
    "            else: # erreur dans la prediciton\n",
    "                if prediction == 1:\n",
    "                    FP += 1\n",
    "                else:\n",
    "                    FN += 1\n",
    "        return (TP,TN,FP,FN)\n",
    "\n",
    "def compute_single_prediction_single_caracteristique(id: str, hyperparameters: dict, caracteristique: str) -> int:  \n",
    "    if caracteristique[-1:] == 'i':\n",
    "        # we compute the complement of caracteristique 'caracteristique[:-1]'\n",
    "        # ex: caracteristique '10i' will compute the complement of caracteristique '10'\n",
    "        return 1-globals()['calcul_caracteristique'+caracteristique[:-1]](id, hyperparameters, caracteristique)\n",
    "    return globals()['calcul_caracteristique'+caracteristique](id, hyperparameters, caracteristique)\n",
    "\n",
    "def compute_single_prediction(id: str, hyperparameters: dict) -> int:  \n",
    "    valeurs_caracteristiques_a_utiliser = []\n",
    "    for c in hyperparameters['caracteristiques_a_utiliser'].split('+'):\n",
    "        valeurs_caracteristiques_a_utiliser.append(compute_single_prediction_single_caracteristique(id, hyperparameters, c))\n",
    "    if not all_elements_same(valeurs_caracteristiques_a_utiliser):\n",
    "        return hyperparameters['label_si_resultats_differents']\n",
    "    return valeurs_caracteristiques_a_utiliser[0]\n",
    "    \n",
    "def all_elements_same(data):\n",
    "    first_element = data[0]\n",
    "    return all(element == first_element for element in data)\n",
    "\n",
    "def compute_toutes_les_predictions(hyperparameters: dict) -> dict:\n",
    "    id_to_predictions = dict()\n",
    "    for id in id_to_data.keys():\n",
    "        id_to_predictions[id] = compute_single_prediction(id, hyperparameters)\n",
    "    return id_to_predictions\n",
    "    \n",
    "def train(hyperparameters: dict, verbose: bool) -> dict:\n",
    "    id_to_predictions = compute_toutes_les_predictions(hyperparameters)\n",
    "    (TP,TN,FP,FN) = compute_matrice_de_confusion(id_to_predictions, id_to_target)\n",
    "    metrics = dict()\n",
    "    metrics['TP'] = TP\n",
    "    metrics['TN'] = TN\n",
    "    metrics['FP'] = FP\n",
    "    metrics['FN'] = FN\n",
    "    metrics['error_target0'] = compute_error_target0(TP,TN,FP,FN)\n",
    "    metrics['error_target1'] = compute_error_target1(TP,TN,FP,FN)\n",
    "    current_error = compute_error(TP,TN,FP,FN)\n",
    "    metrics['erreur'] = current_error\n",
    "    update_stats_hpo(current_error, hyperparameters)\n",
    "    global last_time_display_stats_hpo\n",
    "    if (time.time()-last_time_display_stats_hpo)>600:\n",
    "        save_stats_hpo(False)\n",
    "        last_time_display_stats_hpo = time.time()\n",
    "    global current_lowest_error\n",
    "    if not current_lowest_error or current_error<current_lowest_error:\n",
    "        current_lowest_error = current_error\n",
    "        if verbose:\n",
    "            print(f\"new lowest error {round(current_error,4)} for hyperparameters {[c for c in hyperparameters.items() if c[1] is not None]}\")\n",
    "        save_model(hyperparameters, metrics)\n",
    "        save_stats_hpo(False)\n",
    "    return metrics\n",
    "\n",
    "    \n",
    "def update_stats_hpo(error:float, hyperparameters: dict) -> None:\n",
    "    for hpo_key, hpo_value in hyperparameters.items():\n",
    "        if hpo_value is None:\n",
    "            continue\n",
    "        if hpo_key not in stats_hpo:\n",
    "            stats_hpo[hpo_key] = dict()\n",
    "        if hpo_value not in stats_hpo[hpo_key]:\n",
    "            stats_hpo[hpo_key][hpo_value] = [0,0]\n",
    "        stats_hpo[hpo_key][hpo_value][0] += 1\n",
    "        stats_hpo[hpo_key][hpo_value][1] += error\n",
    "\n",
    "    \n",
    "# the objective used for Hyperparameters Optimization (HPO)\n",
    "# it is the function to minimize\n",
    "def objective(sample_from_search_space):\n",
    "    hyperparameters = fix_hyperparameters(sample_from_search_space)\n",
    "    model_name = get_model_name(hyperparameters)\n",
    "    if model_name in already_processed_model_names_with_hpo:\n",
    "        metrics = already_processed_model_names_with_hpo[model_name]\n",
    "    else:\n",
    "        metrics = train(hyperparameters, True)\n",
    "        already_processed_model_names_with_hpo[model_name] = metrics\n",
    "    # we want to minimize this mettric ('erreur')\n",
    "    return metrics['erreur']\n",
    "\n",
    "hpo_session_id = str(int(100*time.time()))\n",
    "\n",
    "def save_stats_hpo(display: bool):\n",
    "    res = stats_hpo_to_str()\n",
    "    try:\n",
    "        path = os.path.join(directory, 'hpo_'+hpo_session_id+\".txt\")\n",
    "        with open(path, 'w') as f:\n",
    "            f.write(res)\n",
    "    except Exception as e:\n",
    "        print(f'failed to save hp')\n",
    "    if display:\n",
    "        print(res)\n",
    "\n",
    "# path to the last model saved\n",
    "last_path_for_save_model = None\n",
    "        \n",
    "def save_model(hyperparameters: dict, metrics: dict) -> None:\n",
    "    global last_path_for_save_model\n",
    "    try:\n",
    "        erreur = metrics['erreur']\n",
    "        path = os.path.join(directory, 'hpo_'+hpo_session_id+'_'+hyperparameters['caracteristiques_a_utiliser']+'_'+str(erreur)+\".txt\")\n",
    "        with open(path, 'w') as f:\n",
    "            text = hyperparameters_to_str(hyperparameters)\n",
    "            for m, v in metrics.items():\n",
    "                text += f'\\n#{m}={v}'\n",
    "            f.write(text)\n",
    "        try:\n",
    "            if last_path_for_save_model and os.path.isfile(last_path_for_save_model):\n",
    "                os.remove(last_path_for_save_model)\n",
    "        except Exception as e:\n",
    "            print(f'failed to delete file {last_path_for_save_model}: {e}')\n",
    "        last_path_for_save_model = path\n",
    "    except Exception as e:\n",
    "        print(f'failed to save hp: {e}')\n",
    "    \n",
    "def stats_hpo_to_str() -> str:\n",
    "    max_intervals = 10\n",
    "    result = \"\"\n",
    "    for hpo_key, hpo_key_stats in stats_hpo.items():\n",
    "        result += f\"stats for key '{hpo_key}':\\n\"\n",
    "        all_values = list(hpo_key_stats.keys())\n",
    "        old_value_to_new_value = dict()\n",
    "        if len(all_values)>max_intervals and (isinstance(all_values[0], int) or isinstance(all_values[0], float)):\n",
    "            min_value = float(min(all_values))\n",
    "            max_value = float(max(all_values))\n",
    "            for v in all_values:\n",
    "                index_interval = int (max_intervals * (float(v-min_value)/(max_value-min_value)))\n",
    "                index_interval = min(index_interval, max_intervals-1)\n",
    "                min_value_interval = min_value+index_interval* (max_value-min_value)/max_intervals\n",
    "                max_value_interval = min_value_interval+ (max_value-min_value)/max_intervals\n",
    "                new_key = f'[{round(min_value_interval,2)}, {round(max_value_interval,2)}]'\n",
    "                if new_key not in old_value_to_new_value:\n",
    "                    old_value_to_new_value[new_key] = [0,0]\n",
    "                old_value_to_new_value[new_key][0] += hpo_key_stats[v][0]\n",
    "                old_value_to_new_value[new_key][1] += hpo_key_stats[v][1]\n",
    "        else:\n",
    "            for v in all_values:\n",
    "                old_value_to_new_value[v] = hpo_key_stats[v]     \n",
    "        \n",
    "        for value, value_stats in sorted(old_value_to_new_value.items(), key=lambda item: item[1][1]/item[1][0], reverse=True):\n",
    "            count = value_stats[0]\n",
    "            avg_error = value_stats[1]/count\n",
    "            result += f'\\t{value} : {avg_error} ({count} samples)\\n'\n",
    "    return result\n",
    "        \n",
    "def extract_caracteristique_id(key: str):\n",
    "    if key == 'caracteristiques_a_utiliser' or key == 'label_si_resultats_differents':\n",
    "        return None\n",
    "    splitted = key.split('_')\n",
    "    if len(splitted)>=2 and len(splitted[-1]) >=1 and splitted[-1][0].isdigit():\n",
    "        return splitted[-1]\n",
    "    return None\n",
    "\n",
    "# When conducting an HPO search, some hyperparameters may exhibit inconsistent values.\n",
    "# This method aims to address those inconsistencies.\n",
    "def fix_hyperparameters(hyperparameters: dict) -> dict :\n",
    "    res = dict(hyperparameters)\n",
    "    for key in list(res.keys()):\n",
    "        caracteristique_id = extract_caracteristique_id(key)\n",
    "        if caracteristique_id and caracteristique_id not in res['caracteristiques_a_utiliser'].split('+'):\n",
    "            del res[key]\n",
    "    if '+' not in res['caracteristiques_a_utiliser']:\n",
    "        res['label_si_resultats_differents'] = None\n",
    "    return res\n",
    "\n",
    "\n",
    "# Transform the dictionary of hyperparameters 'hyperparameters' into string.\n",
    "def hyperparameters_to_str(hyperparameters: dict) -> str:\n",
    "    sorted_hyperparameters = sorted (hyperparameters.items())\n",
    "    return \"\\n\".join([hyperparameter_name+\" = \"+str(hyperparameter_value) for (hyperparameter_name,hyperparameter_value) in sorted_hyperparameters if hyperparameter_value is not None])\n",
    "\n",
    "def get_model_name(hyperparameters: dict) -> str:\n",
    "    file_content = hyperparameters_to_str(hyperparameters)\n",
    "    return compute_hash(file_content, 10)\n",
    "\n",
    "def compute_hash(input_string, max_length):\n",
    "    # Calculate MD5 hash of the input string\n",
    "    md5_hash = hashlib.md5(input_string.encode('ascii')).hexdigest().upper()\n",
    "    # Return the hash truncated to the max_length\n",
    "    return md5_hash[:max_length]\n",
    "\n",
    "def launch_hpo_for_transformer_model(max_evals: int):\n",
    "    seed = random.randint(0, 100000)\n",
    "    print(f'using seed: {seed}')\n",
    "    rstate = np.random.default_rng(seed)\n",
    "    best_indexes = fmin(\n",
    "        fn=objective,  # \"Loss\" function to minimize\n",
    "        space=search_space,  # Hyperparameter space\n",
    "        #algo=hyperopt_rand.suggest, #Random Search\n",
    "        algo=tpe.suggest,  # Tree-structured Parzen Estimator (TPE)\n",
    "        max_evals=max_evals,  # Perform 'max_evals' trials\n",
    "        max_queue_len = 10,\n",
    "        rstate =rstate,\n",
    "    )\n",
    "\n",
    "    # Get the best parameters\n",
    "    best  = space_eval(search_space, best_indexes)\n",
    "    print(f\"Found minimum after {max_evals} trials:\")\n",
    "    print([c for c in best.items() if c[1] is not None])\n",
    "    return best\n",
    "\n",
    "\n",
    "\n",
    "def float_range(x1: float, x2: float, count:int = 100) -> List[float]:\n",
    "    epsilon = (x2-x1)/count\n",
    "    # Generate the range of float values with the specified step\n",
    "    return list(np.arange(x1, x2, epsilon))\n",
    "\n",
    "def int_range(x:int, y:int, count:int = 100) -> List[int]:\n",
    "    epsilon = int ((y+1-x)/count )\n",
    "    epsilon = max(epsilon, 1)\n",
    "    return list(range(x, y+1,epsilon))\n",
    "\n",
    "\n",
    "\n",
    "search_space = {\n",
    "\n",
    "    # caracteristique 3: sujet sain si l'étendue est inférieure à un seuil.\n",
    "    'seuil_3': hp.choice('seuil_3', int_range(50,200, 150)),\n",
    "\n",
    "    # caracteristique 7A: sujet sain si l'écart type est inférieur à un seuil.\n",
    "    'seuil_7A': hp.choice('seuil_7A', float_range(15.0, 25.0, 100)),\n",
    "    \n",
    "    # caracteristique 7C: sujet sain si la variance de est inférieure à un seuil.\n",
    "    'seuil_7C': hp.choice('seuil_7C', int_range(400, 600, 200)),\n",
    "    \n",
    "    # caracteristique 15: sujet sain si l'écart interquartile est inférieur à un seuil\n",
    "    'seuil_15': hp.choice('seuil_15', float_range(10, 50, 100)),\n",
    "\n",
    "    'caracteristiques_a_utiliser': hp.choice('caracteristiques_a_utiliser', ['7C+15']),\n",
    "    'label_si_resultats_differents': hp.choice('label_si_resultats_differents', [0, 1]),\n",
    "}\n",
    "\n",
    "\n",
    "if len(sys.argv) >=2 and str.isdigit(sys.argv[1][0]):\n",
    "    caracteristiques_a_utiliser = sys.argv[1].split(',')\n",
    "    print(f'caracteristiques_a_utiliser will be set to {caracteristiques_a_utiliser}')\n",
    "    search_space['caracteristiques_a_utiliser'] =  hp.choice('caracteristiques_a_utiliser', caracteristiques_a_utiliser)\n",
    "\n",
    "\n",
    "max_evals = 1000\n",
    "if len(sys.argv) >=3 and str.isdigit(sys.argv[2]):\n",
    "    print(f'max_evals will be set to {sys.argv[2]}')\n",
    "    max_evals = int(sys.argv[2])\n",
    "print(f'max_evals value is {max_evals}')\n",
    "\n",
    "already_processed_model_names_with_hpo = dict()\n",
    "start_time = time.time()\n",
    "# Uncomment following line to enable HPO\n",
    "#best = launch_hpo_for_transformer_model(max_evals)\n",
    "print(f'hpo took {round(time.time()-start_time,2)}s')\n",
    "save_stats_hpo(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c810a07e",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">\n",
    "<span style=\"font-size: 48px;\">1ère partie</span>\n",
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e92525",
   "metadata": {},
   "source": [
    "## Faire constater par l'étudiant que l'étendue est plus importante pour les sujets malades que pour les sujets sains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f843946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_stats_etendue():\n",
    "    etendue_target_0 =[]\n",
    "    etendue_target_1 =[]\n",
    "    for id in id_to_data.keys():\n",
    "        etendue = compute_id_range(id)\n",
    "        if 0 == id_to_target[id]:\n",
    "            etendue_target_0.append(etendue)\n",
    "        else:\n",
    "            etendue_target_1.append(etendue)\n",
    "    print(f\"Valeur de l'étendue:\")\n",
    "    print(f'\\tMoyenne pour les sujets sains = {round(np.mean(etendue_target_0),2)}')\n",
    "    print(f'\\tMoyenne pour les sujets malades = {round(np.mean(etendue_target_1),2)}')\n",
    "display_stats_etendue()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d72f86c",
   "metadata": {},
   "source": [
    "# Affichage de la qualité de  l'outil en fonction de la valeur de la caractéristique: l'étendue.\n",
    "## Au dessus de ce seuil, on considère que le sujet est malade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296c083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import make_interp_spline\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "valeurs_caracteristique = []\n",
    "erreur_caracteristique = []\n",
    "for seuil_etendue in range(0, 200, 10):\n",
    "    config = {'caracteristiques_a_utiliser': '3', 'seuil_3': seuil_etendue}\n",
    "    erreur = train(config, False)['erreur']\n",
    "    valeurs_caracteristique.append(seuil_etendue)\n",
    "    erreur_caracteristique.append(erreur)\n",
    "\n",
    "x_dense = np.linspace(min(valeurs_caracteristique), max(valeurs_caracteristique), 500)  # 500 points pour une courbe lisse\n",
    "spline = make_interp_spline(valeurs_caracteristique, erreur_caracteristique)\n",
    "y_dense = spline(x_dense)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(x_dense, y_dense, label='Erreur', color='b')\n",
    "plt.scatter(valeurs_caracteristique, erreur_caracteristique, color='r')\n",
    "plt.gca().tick_params(axis='y', which='major', labelsize=20) \n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1, decimals=0))\n",
    "plt.xticks(fontsize=20)\n",
    "plt.xlabel(\"Etendue\", fontsize=20)\n",
    "plt.ylabel('Erreur', fontsize=20)\n",
    "plt.xlim(min(valeurs_caracteristique), max(valeurs_caracteristique))\n",
    "plt.title(\"Erreur (%) en fonction de l'étendue\", fontsize=20)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2d5922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l'étudiant devra remplacer le 100 ci dessous\n",
    "\n",
    "seuil_etendue = 100\n",
    "\n",
    "config = {'caracteristiques_a_utiliser': '3', 'seuil_3': seuil_etendue}\n",
    "metrics = train(config, False)\n",
    "print(f\"Erreur obtenue: {round(100*metrics['erreur'],1)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6815e02",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">\n",
    "<span style=\"font-size: 48px;\">2ème partie</span>\n",
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f9685c",
   "metadata": {},
   "source": [
    "# Faire constater par l'étudiant que l'écart type observé pour les sujets malades est en moyenne plus élevé que l'écart type observé pour les sujets sains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b52e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_stats_std_dev():\n",
    "    std_dev_target_0 =[]\n",
    "    srd_dev_target_1 =[]\n",
    "    for id in id_to_data.keys():\n",
    "        std_dev = compute_id_std_dev(id)\n",
    "        if 0 == id_to_target[id]:\n",
    "            std_dev_target_0.append(std_dev)\n",
    "        else:\n",
    "            srd_dev_target_1.append(std_dev)\n",
    "    print(f'Ecart type:')\n",
    "    print(f'\\tMoyenne pour les sujets sains = {round(np.mean(std_dev_target_0),2)}')\n",
    "    print(f'\\tMoyenne pour les sujets malades = {round(np.mean(srd_dev_target_1),2)}')\n",
    "display_stats_std_dev()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1bacdc",
   "metadata": {},
   "source": [
    "# Affichage de la qualité de  l'outil en fonction du seuil d'écart type choisi pour identifier les sujets malades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba74d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "valeurs_caracteristique = []\n",
    "erreur_caracteristique = []\n",
    "for threshold_ecart_type in range(0,30+1,1):\n",
    "    config = {'caracteristiques_a_utiliser': '7A', 'seuil_7A': threshold_ecart_type}\n",
    "    erreur = train(config, False)['erreur']\n",
    "    valeurs_caracteristique.append(threshold_ecart_type)\n",
    "    erreur_caracteristique.append(erreur)\n",
    "\n",
    "x_dense = np.linspace(min(valeurs_caracteristique), max(valeurs_caracteristique), 500)  # 500 points pour une courbe lisse\n",
    "spline = make_interp_spline(valeurs_caracteristique, erreur_caracteristique)\n",
    "y_dense = spline(x_dense)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(x_dense, y_dense, label='Erreur', color='b')\n",
    "plt.scatter(valeurs_caracteristique, erreur_caracteristique, color='r')\n",
    "plt.gca().tick_params(axis='y', which='major', labelsize=20) \n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "plt.xticks(fontsize=20)\n",
    "plt.xlabel(\"Ecart type\", fontsize=20)\n",
    "plt.ylabel('Erreur', fontsize=20)\n",
    "plt.title(\"Erreur en fonction du seuil de l'écart type\", fontsize=20)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e16f96a",
   "metadata": {},
   "source": [
    "# On demande à l'étudiant de choisir le seuil pour l'écart type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fedb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l'étudiant devra remplacer le 10 ci dessous\n",
    "seuil_ecart_type = 10\n",
    "\n",
    "config = {'caracteristiques_a_utiliser': '7A', 'seuil_7A': seuil_ecart_type}\n",
    "metrics = train(config, False)\n",
    "print(f\"Erreur obtenue: {round(100*metrics['erreur'],1)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fe9696",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">\n",
    "<span style=\"font-size: 48px;\">3ème partie</span>\n",
    "<hr style=\"height:2px; border-width:0; color:black; background-color:black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99169c8",
   "metadata": {},
   "source": [
    "# On combine les 2 caractéristiques précédentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e460a90",
   "metadata": {},
   "source": [
    "# PRIVE: Affichage de graphiques montrant les sujets sains et les sujets malades en fonction de 2 caractéristiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be28d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_plot(x_method, x_method_name:str, y_method, y_method_name:str):\n",
    "    label0_coordinates = []\n",
    "    label1_coordinates = []\n",
    "    for id in id_to_data.keys():\n",
    "        x =x_method(id)\n",
    "        y =y_method(id)\n",
    "        if id_to_target[id] == 0:\n",
    "            label0_coordinates.append((x,y))\n",
    "        else:\n",
    "            label1_coordinates.append((x,y))\n",
    "    x_label0, y_label0 = zip(*label0_coordinates)\n",
    "    plt.scatter(x_label0, y_label0, color='green', label='Sains')\n",
    "    x_label1, y_label1 = zip(*label1_coordinates)\n",
    "    plt.scatter(x_label1, y_label1, color='red', label='Malades')\n",
    "    #plt.title('Sujets sains et malades')\n",
    "    plt.xlabel(x_method_name)\n",
    "    plt.ylabel(y_method_name)\n",
    "    # Adding a legend to distinguish the series\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "@functools.lru_cache(maxsize=None)\n",
    "def compute_id_variance(id: int) -> float:\n",
    "    std_dev = compute_id_std_dev(id)\n",
    "    return std_dev*std_dev\n",
    "\n",
    "\n",
    "caracteristiques = [(compute_id_std_dev, \"Ecart type\"), \n",
    "                    (compute_id_range, \"Etendue\"),\n",
    "                    (compute_id_variance, \"Variance\"),\n",
    "                    (compute_id_interquartile_range, \"Ecart interquartile\")\n",
    "                   ]\n",
    "\n",
    "for (x_method, x_method_name) in caracteristiques:\n",
    "    for (y_method, y_method_name) in caracteristiques:\n",
    "        if x_method_name == y_method_name:\n",
    "            continue\n",
    "        if min(x_method_name,y_method_name) == \"Ecart type\" and max(x_method_name,y_method_name) == \"Variance\":\n",
    "            continue\n",
    "        display_plot(x_method, x_method_name, y_method, y_method_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8772350",
   "metadata": {},
   "source": [
    "# On demande à l'étudiant de choisir la valeur de ces 2 caractéristiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddd8371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l'étudiant devra remplacer les 2 valeurs ci dessous\n",
    "\n",
    "seuil_ecart_type = 10\n",
    "seuil_etendue = 100\n",
    "\n",
    "config = {'caracteristiques_a_utiliser': '7A+3', 'seuil_7A': seuil_ecart_type, 'seuil_3': seuil_etendue,'label_si_resultats_differents': 1}\n",
    "metrics = train(config, False)\n",
    "print(f\"Erreur obtenue: {round(100*metrics['erreur'],1)}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
